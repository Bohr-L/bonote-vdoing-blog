---
title:  百万级别数据的 Excel 如何快速导入到数据库中
date: 2025-12-28 21:50:45
permalink: /pages/interview/data/
categories:
  - 常见面试题
  - 数据处理与存储类
tags:
  - 
---
Excel 数据导入慢的核心问题是 “单条读取 + 单条插入” 的低效模式，优化方案如下：

- **步骤 1：预处理 Excel，避免格式干扰**：将.xlsx/.xls 转为.csv 格式（减少 Excel 解析开销），或用 Alibaba EasyExcel（轻量级解析库，避免 POI 的内存溢出问题）读取数据，跳过空行、格式错误行。
- **步骤 2：批量插入替代单条插入**：读取数据时按批次（如 1000 条 / 批）缓存，通过数据库的批量插入语法（如 MySQL 的`INSERT INTO table (col1,col2) VALUES (v1,v2),(v3,v4)...`）或 MyBatis 的`<foreach>`标签批量提交，减少数据库连接次数（单次连接处理批量数据，降低 TCP 握手和事务提交开销）。
- **步骤 3：优化数据库配置**：关闭自动提交事务（`set autocommit=0`），批量插入后手动提交；临时关闭索引（插入完成后重建，避免频繁索引更新）；若使用 InnoDB，调整`innodb_buffer_pool_size`（增大缓存）、`innodb_flush_log_at_trx_commit=2`（降低刷盘频率，适用于非核心数据）。
- **步骤 4：分布式导入（超大规模场景）**：若数据超千万级，用 Spark、Flink 等分布式框架读取 Excel 文件（支持分布式存储如 HDFS），并行分批次写入数据库，利用分布式计算提升效率。
